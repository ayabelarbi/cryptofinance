{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 1.1: Uniformity Test of SHA-256 Hash Function\n",
        "\n",
        "## Goal\n",
        "\n",
        "The objective of this exercise is to empirically verify that **SHA-256 behaves like a pseudo-random function** by testing whether its output follows a uniform distribution.\n",
        "\n",
        "### Why This Matters\n",
        "\n",
        "The uniformity of cryptographic hash functions is a fundamental assumption in blockchain technology and cryptography:\n",
        "\n",
        "1. **Security of Proof-of-Work**: If hash outputs were biased toward certain values, miners could exploit this to find valid blocks more efficiently, undermining the security model.\n",
        "\n",
        "2. **Random Oracle Model**: Many cryptographic proofs assume hash functions behave as \"random oracles\" — functions that return uniformly random outputs for each unique input.\n",
        "\n",
        "3. **Fair Distribution**: In applications like hash-based commitments, digital signatures, and address generation, uniformity ensures no predictable patterns exist.\n",
        "\n",
        "### Methodology\n",
        "\n",
        "We test uniformity using the **chi-square goodness-of-fit test**:\n",
        "\n",
        "1. **Data Collection**: Generate $n$ unique inputs and compute SHA-256 hashes\n",
        "2. **Feature Extraction**: Extract the first 16 bits of each hash (values in $[0, 65535]$)\n",
        "3. **Bucketing**: Divide the range into $k$ equal-width bins and count observations per bin\n",
        "4. **Statistical Test**: Compare observed counts against expected counts under uniform distribution\n",
        "\n",
        "**Hypotheses**:\n",
        "- $H_0$: The first 16 bits of SHA-256 outputs are uniformly distributed\n",
        "- $H_1$: The distribution is not uniform\n",
        "\n",
        "**Test Statistic**:\n",
        "$$\\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E)^2}{E}$$\n",
        "\n",
        "where $O_i$ is the observed count in bin $i$ and $E = n/k$ is the expected count per bin.\n",
        "\n",
        "**Decision Rule**: Reject $H_0$ if p-value $< \\alpha$ (typically 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHVq0guLvf-7"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "def execute_distribution_analysis(sample_count=10000, bucket_count=50):\n",
        "    print(\"--- Running Uniformity Test ---\")\n",
        "    hash_values = []\n",
        "    for idx in range(sample_count):\n",
        "        # Generate hash from unique inputs\n",
        "        digest = hashlib.sha256(f\"salt_{idx}\".encode()).hexdigest()\n",
        "        # Extract first 16 bits (4 hex characters) as integer\n",
        "        hash_values.append(int(digest[:4], 16))\n",
        "\n",
        "    # Perform Statistical Test\n",
        "    observed_counts, bin_edges = np.histogram(hash_values, bins=bucket_count, range=(0, 65535))\n",
        "    expected_counts = np.full(bucket_count, sample_count / bucket_count)\n",
        "    chi_squared, p_val = stats.chisquare(f_obs=observed_counts, f_exp=expected_counts)\n",
        "\n",
        "    # Generate Plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(bin_edges[:-1], observed_counts, width=(65535/bucket_count), align='edge', color='skyblue', alpha=0.8)\n",
        "    plt.axhline(y=sample_count/bucket_count, color='red', linestyle='--', label='Expected')\n",
        "    plt.title(f\"SHA-256 Uniformity (p-value: {p_val:.4f})\")\n",
        "    plt.savefig('uniformity_dist.png')\n",
        "    print(f\"Chi2: {chi_squared:.2f}, p-value: {p_val:.4f}\\n\")\n",
        "\n",
        "def execute_mining_simulation(success_count=100, leading_zeros=4):\n",
        "    print(\"--- Running Proof-of-Work Timing Test ---\")\n",
        "    target_prefix = '0' * leading_zeros\n",
        "    time_intervals = []\n",
        "    counter = 0\n",
        "\n",
        "    for trial in range(success_count):\n",
        "        start_time = time.perf_counter()\n",
        "        while True:\n",
        "            digest = hashlib.sha256(f\"block_{counter}\".encode()).hexdigest()\n",
        "            if digest.startswith(target_prefix):\n",
        "                time_intervals.append(time.perf_counter() - start_time)\n",
        "                counter += 1\n",
        "                break\n",
        "            counter += 1\n",
        "\n",
        "    time_intervals = np.array(time_intervals)\n",
        "    avg_time, std_time = np.mean(time_intervals), np.std(time_intervals)\n",
        "\n",
        "    # Kolmogorov-Smirnov Test for Exponential distribution\n",
        "    ks_statistic, ks_pvalue = stats.kstest(time_intervals, 'expon', args=(0, avg_time))\n",
        "\n",
        "    # Generate Plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(time_intervals, bins=20, density=True, color='green', alpha=0.6, label='Observed')\n",
        "    time_axis = np.linspace(0, max(time_intervals), 100)\n",
        "    plt.plot(time_axis, stats.expon.pdf(time_axis, scale=avg_time), 'r-', label='Exponential PDF')\n",
        "    plt.title(f\"PoW Inter-arrival Times (p-value: {ks_pvalue:.4f})\")\n",
        "    plt.legend()\n",
        "    plt.savefig('pow_exponential_dist.png')\n",
        "\n",
        "    print(f\"Mean: {avg_time:.4f}s, Std Dev: {std_time:.4f}s\")\n",
        "    print(f\"K-S Test p-value: {ks_pvalue:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    execute_distribution_analysis()\n",
        "    execute_mining_simulation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aywFuMOQvlpC"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import secrets\n",
        "import math\n",
        "from typing import List, Dict, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "print(\"Saving plots to:\", os.getcwd())\n",
        "\n",
        "\n",
        "# --- Optional: SciPy for exact p-value (recommended) ---\n",
        "try:\n",
        "    from scipy.stats import chi2\n",
        "    HAS_SCIPY = True\n",
        "except ImportError:\n",
        "    HAS_SCIPY = False\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Hash extraction (first 16 bits)\n",
        "# ---------------------------\n",
        "def extract_hash_prefix(input_data: bytes) -> int:\n",
        "    \"\"\"\n",
        "    Compute SHA-256(input_data) and extract first 16 bits (first 2 bytes) as integer in [0, 65535].\n",
        "    \"\"\"\n",
        "    hash_digest = hashlib.sha256(input_data).digest()\n",
        "    return int.from_bytes(hash_digest[0:2], byteorder=\"big\", signed=False)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Chi-square computation + p-value\n",
        "# ---------------------------\n",
        "def compute_chi_square(freq_observed: List[int], freq_expected: float) -> float:\n",
        "    return sum((obs - freq_expected) ** 2 / freq_expected for obs in freq_observed)\n",
        "\n",
        "\n",
        "def compute_pvalue(chi2_value: float, degrees_freedom: int) -> Tuple[float, str]:\n",
        "    \"\"\"\n",
        "    Returns (p_value, description). Uses SciPy if available, else Wilson-Hilferty approximation.\n",
        "    \"\"\"\n",
        "    if HAS_SCIPY:\n",
        "        probability = chi2.sf(chi2_value, degrees_freedom)  # upper tail probability\n",
        "        return probability, \"exact (SciPy)\"\n",
        "    # Wilson-Hilferty transform (accurate for df >= ~30)\n",
        "    z_score = ((chi2_value / degrees_freedom) ** (1 / 3) - (1 - 2 / (9 * degrees_freedom))) / math.sqrt(2 / (9 * degrees_freedom))\n",
        "    probability = 0.5 * math.erfc(z_score / math.sqrt(2))\n",
        "    return probability, \"approx (no SciPy)\"\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Bucketing (k bins over 0..65535)\n",
        "# ---------------------------\n",
        "def get_bin_index(value: int, total_bins: int) -> int:\n",
        "    \"\"\"\n",
        "    Map value in [0,65535] to [0, total_bins-1] using equal-width bins.\n",
        "    \"\"\"\n",
        "    bin_width = 65536 / total_bins\n",
        "    bin_idx = int(value / bin_width)\n",
        "    return min(bin_idx, total_bins - 1)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Input generation (repeatability)\n",
        "# ---------------------------\n",
        "def create_test_inputs(total_samples: int, generation_mode: str, run_number: int) -> List[bytes]:\n",
        "    \"\"\"\n",
        "    Generate total_samples unique inputs as bytes, depending on generation_mode:\n",
        "    - \"sequential\": b\"input1\", b\"input2\", ...\n",
        "      NOTE: deterministic -> repeating trials gives identical results.\n",
        "    - \"sequential_with_trial_prefix\": b\"trial{run_number}|input1\", ...\n",
        "    - \"random_hex\": random 16-byte tokens + index (unique with overwhelming probability)\n",
        "    \"\"\"\n",
        "    if generation_mode == \"sequential\":\n",
        "        return [f\"input{i}\".encode(\"utf-8\") for i in range(1, total_samples + 1)]\n",
        "\n",
        "    if generation_mode == \"sequential_with_trial_prefix\":\n",
        "        run_prefix = f\"trial{run_number}|\".encode(\"utf-8\")\n",
        "        return [run_prefix + f\"input{i}\".encode(\"utf-8\") for i in range(1, total_samples + 1)]\n",
        "\n",
        "    if generation_mode == \"random_hex\":\n",
        "        # Use secrets for good randomness; attach i to guarantee uniqueness\n",
        "        result = []\n",
        "        for i in range(1, total_samples + 1):\n",
        "            random_token = secrets.token_hex(16).encode(\"utf-8\")  # 32 hex chars\n",
        "            result.append(random_token + b\"|\" + str(i).encode(\"utf-8\"))\n",
        "        return result\n",
        "\n",
        "    raise ValueError(f\"Unknown generation_mode: {generation_mode}\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Single trial execution\n",
        "# ---------------------------\n",
        "def perform_single_trial(total_samples: int = 10_000, total_bins: int = 100, significance_level: float = 0.05,\n",
        "              generation_mode: str = \"sequential_with_trial_prefix\", run_number: int = 1) -> Dict:\n",
        "    test_inputs = create_test_inputs(total_samples, generation_mode, run_number)\n",
        "\n",
        "    bin_counts = [0] * total_bins\n",
        "    for data in test_inputs:\n",
        "        hash_val = extract_hash_prefix(data)\n",
        "        bin_counts[get_bin_index(hash_val, total_bins)] += 1\n",
        "\n",
        "    expected_per_bin = total_samples / total_bins\n",
        "    chi2_result = compute_chi_square(bin_counts, expected_per_bin)\n",
        "    degrees_freedom = total_bins - 1\n",
        "    p_val, p_method = compute_pvalue(chi2_result, degrees_freedom)\n",
        "\n",
        "    return {\n",
        "        \"trial_id\": run_number,\n",
        "        \"pattern\": generation_mode,\n",
        "        \"num_samples\": total_samples,\n",
        "        \"k_bins\": total_bins,\n",
        "        \"expected\": expected_per_bin,\n",
        "        \"observed\": bin_counts,\n",
        "        \"chi2_stat\": chi2_result,\n",
        "        \"df\": degrees_freedom,\n",
        "        \"p_value\": p_val,\n",
        "        \"p_note\": p_method,\n",
        "        \"alpha\": significance_level,\n",
        "        \"reject_H0\": (p_val < significance_level),\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Plotting functions\n",
        "# ---------------------------\n",
        "def render_bucket_histogram(bin_counts, expected_val, chart_title, output_file):\n",
        "    plt.figure()\n",
        "    x_positions = list(range(len(bin_counts)))\n",
        "    plt.bar(x_positions, bin_counts)\n",
        "    plt.axhline(expected_val)\n",
        "    plt.title(chart_title)\n",
        "    plt.xlabel(\"Bucket index (0..k-1)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_file, dpi=160)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def render_pvalue_histogram(pvalue_list: List[float], significance_level: float, chart_title: str, output_file: str):\n",
        "    plt.figure()\n",
        "    plt.hist(pvalue_list, bins=10)\n",
        "    plt.axvline(significance_level)\n",
        "    plt.title(chart_title)\n",
        "    plt.xlabel(\"p-value\")\n",
        "    plt.ylabel(\"frequency\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_file, dpi=160)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Repeatability runner\n",
        "# ---------------------------\n",
        "def execute_repeatability_test(num_trials: int = 20,\n",
        "                      total_samples: int = 10_000,\n",
        "                      total_bins: int = 100,\n",
        "                      significance_level: float = 0.05,\n",
        "                      generation_mode: str = \"sequential_with_trial_prefix\"):\n",
        "    trial_results = []\n",
        "    for t in range(1, num_trials + 1):\n",
        "        trial_results.append(perform_single_trial(total_samples, total_bins, significance_level, generation_mode, run_number=t))\n",
        "\n",
        "    pvalue_list = [r[\"p_value\"] for r in trial_results]\n",
        "    rejection_count = sum(1 for r in trial_results if r[\"reject_H0\"])\n",
        "\n",
        "    stats_summary = {\n",
        "        \"trials\": num_trials,\n",
        "        \"pattern\": generation_mode,\n",
        "        \"alpha\": significance_level,\n",
        "        \"rejects\": rejection_count,\n",
        "        \"reject_rate\": rejection_count / num_trials,\n",
        "        \"p_min\": min(pvalue_list),\n",
        "        \"p_max\": max(pvalue_list),\n",
        "        \"p_mean\": sum(pvalue_list) / len(pvalue_list),\n",
        "        \"p_note\": trial_results[0][\"p_note\"] if trial_results else \"\",\n",
        "    }\n",
        "    return trial_results, stats_summary\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Main execution block\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Single trial (for main report figure) ---\n",
        "    single_result = perform_single_trial(\n",
        "        total_samples=10_000,\n",
        "        total_bins=100,\n",
        "        significance_level=0.05,\n",
        "        generation_mode=\"sequential_with_trial_prefix\",  # recommended for repeatability\n",
        "        run_number=1\n",
        "    )\n",
        "\n",
        "    print(\"=== 1.1 Uniformity Test (SHA-256, first 16 bits, chi-square) ===\")\n",
        "    print(f\"Samples: {single_result['num_samples']}\")\n",
        "    print(f\"Bins (k): {single_result['k_bins']}\")\n",
        "    print(f\"Expected per bin (E): {single_result['expected']:.2f}\")\n",
        "    print(f\"Chi-square statistic: {single_result['chi2_stat']:.4f}\")\n",
        "    print(f\"df: {single_result['df']}\")\n",
        "    print(f\"p-value: {single_result['p_value']:.6f} ({single_result['p_note']})\")\n",
        "    print(f\"alpha: {single_result['alpha']}\")\n",
        "    print(\"Decision:\", \"Reject H0\" if single_result[\"reject_H0\"] else \"Fail to reject H0\")\n",
        "\n",
        "    render_bucket_histogram(\n",
        "        single_result[\"observed\"],\n",
        "        single_result[\"expected\"],\n",
        "        chart_title=\"Bucket counts (k=100) for SHA-256 first 16 bits\",\n",
        "        output_file=\"bucket_hist_trial1.png\"\n",
        "    )\n",
        "    print(\"Saved plot: bucket_hist_trial1.png\")\n",
        "\n",
        "    # --- Repeatability: multiple trials (changing inputs across trials) ---\n",
        "    all_results, summary_stats = execute_repeatability_test(\n",
        "        num_trials=30,\n",
        "        total_samples=10_000,\n",
        "        total_bins=100,\n",
        "        significance_level=0.05,\n",
        "        generation_mode=\"sequential_with_trial_prefix\"\n",
        "        # alternatives:\n",
        "        # generation_mode=\"sequential\"   (will repeat identical results each trial)\n",
        "        # generation_mode=\"random_hex\"   (random each time)\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Repeatability summary ===\")\n",
        "    print(f\"Trials: {summary_stats['trials']}, pattern: {summary_stats['pattern']}\")\n",
        "    print(f\"p-values: min={summary_stats['p_min']:.6f}, mean={summary_stats['p_mean']:.6f}, max={summary_stats['p_max']:.6f}\")\n",
        "    print(f\"Rejections at alpha={summary_stats['alpha']}: {summary_stats['rejects']} / {summary_stats['trials']} \"\n",
        "          f\"({summary_stats['reject_rate']*100:.1f}%)\")\n",
        "    print(f\"p-value method: {summary_stats['p_note']}\")\n",
        "\n",
        "    render_pvalue_histogram(\n",
        "        [r[\"p_value\"] for r in all_results],\n",
        "        significance_level=summary_stats[\"alpha\"],\n",
        "        chart_title=\"p-values across repeated trials (chi-square uniformity test)\",\n",
        "        output_file=\"pvalues_repeatability.png\"\n",
        "    )\n",
        "    print(\"Saved plot: pvalues_repeatability.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "### Experimental Results\n",
        "\n",
        "#### Single Trial Analysis\n",
        "| Parameter | Value |\n",
        "|-----------|-------|\n",
        "| Number of samples ($n$) | 10,000 |\n",
        "| Number of bins ($k$) | 100 |\n",
        "| Expected count per bin ($E$) | 100 |\n",
        "| Chi-square statistic ($\\chi^2$) | ~93.78 |\n",
        "| Degrees of freedom ($df$) | 99 |\n",
        "| p-value | ~0.63 |\n",
        "| Significance level ($\\alpha$) | 0.05 |\n",
        "| **Decision** | **Fail to reject $H_0$** |\n",
        "\n",
        "The chi-square statistic of ~93.78 with 99 degrees of freedom yields a p-value of approximately 0.63, which is well above the significance level of 0.05. This means the observed distribution is statistically consistent with a uniform distribution.\n",
        "\n",
        "#### Repeatability Analysis (30 Trials)\n",
        "| Metric | Value |\n",
        "|--------|-------|\n",
        "| Minimum p-value | ~0.035 |\n",
        "| Mean p-value | ~0.49 |\n",
        "| Maximum p-value | ~0.99 |\n",
        "| Rejection rate | ~3.3% (1/30) |\n",
        "\n",
        "The mean p-value of ~0.49 is close to the theoretical expectation of 0.5 under the null hypothesis. The rejection rate of ~3.3% is at or below the expected 5% false positive rate, confirming the test is well-calibrated.\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "#### Visual Evidence\n",
        "The bucket histogram shows counts fluctuating around the expected value of 100, with no systematic bias toward any region of the output space. This is exactly what we would expect from a uniform distribution.\n",
        "\n",
        "#### Statistical Evidence\n",
        "- **High p-value**: A p-value of 0.63 indicates that if the null hypothesis were true (uniform distribution), we would observe a chi-square statistic this extreme or more extreme about 63% of the time. This provides no evidence against uniformity.\n",
        "- **Consistent repeatability**: Across 30 independent trials with different input sets, the p-values are distributed roughly uniformly between 0 and 1, as expected under $H_0$.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "1. **SHA-256 passes the uniformity test**: The first 16 bits of SHA-256 hash outputs are indistinguishable from uniform random values at the 5% significance level.\n",
        "\n",
        "2. **No detectable bias**: There is no evidence that certain hash prefixes are more likely than others, supporting the assumption that SHA-256 behaves like a pseudo-random function.\n",
        "\n",
        "3. **Robust across multiple trials**: The results are consistent and reproducible, with the expected false positive rate under repeated testing.\n",
        "\n",
        "### Implications for Cryptographic Applications\n",
        "\n",
        "These findings support the use of SHA-256 in:\n",
        "- **Proof-of-Work systems**: The uniform distribution ensures that finding a hash below a target threshold has the expected probability, making difficulty calculations reliable.\n",
        "- **Hash-based commitments**: No adversary can predict which inputs will produce hashes in a specific range.\n",
        "- **Address generation**: Cryptocurrency addresses derived from hash functions will be uniformly distributed across the address space.\n",
        "\n",
        "### Limitations\n",
        "\n",
        "1. **Partial output**: We only tested the first 16 bits; the full 256-bit output space would require exponentially more samples to test comprehensively.\n",
        "\n",
        "2. **Statistical vs. cryptographic security**: Passing a statistical uniformity test does not prove cryptographic security — it only provides empirical evidence consistent with the random oracle assumption.\n",
        "\n",
        "3. **Input patterns**: Our test used specific input patterns; adversarially crafted inputs might reveal different behavior (though this would contradict SHA-256's design goals)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
